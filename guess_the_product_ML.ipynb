{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col,udf, col, lower, regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import lit\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Initializing Spark session\n",
    "\n",
    "spark = SparkSession.builder.appName('guess_the_product').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Data Files in Spark dataframe\n",
    "\n",
    "train_data = spark.read.csv('train_set.csv',inferSchema=True,header=True)\n",
    "test_data = spark.read.csv('test_set.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of blank product  category to test data.\n",
    "test_data = test_data.withColumn(\"Product_Category\", lit('vald'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns == test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = train_data.union(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.Product_Category.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lowercase text data.\n",
    "final_df = final_df.select('*', (lower(col('Item_Description')).alias('Lower_Item_Description'))).drop('Item_Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representing target categorical feature to numeric.\n",
    "\n",
    "product_categories = pd.Series(list(final_df.select('Product_Category').distinct().toPandas()['Product_Category']))\n",
    "product_categories = product_categories.to_dict()\n",
    "product_categories = {value : str(key) for (key, value) in product_categories.items()}\n",
    "\n",
    "final_df = final_df.replace(product_categories,subset='Product_Category')\n",
    "final_df = final_df.withColumn(\"label\", col(\"Product_Category\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+-------+----------------+----------------------+-----+\n",
      "|Inv_Id|Vendor_Code|   GL_Code|Inv_Amt|Product_Category|Lower_Item_Description|label|\n",
      "+------+-----------+----------+-------+----------------+----------------------+-----+\n",
      "| 15001|VENDOR-1676|GL-6100410|  83.24|              28|  artworking/typese...|   28|\n",
      "| 15002|VENDOR-1883|GL-2182000|  51.18|              10|  auto leasing corp...|   10|\n",
      "| 15004|VENDOR-1999|GL-6050100|  79.02|              25|  store management ...|   25|\n",
      "| 15005|VENDOR-1771|GL-6101400|   48.5|              22|  store constructio...|   22|\n",
      "| 15006|VENDOR-1331|GL-2182000|  63.35|              29|  jul 2015 aydin co...|   29|\n",
      "+------+-----------+----------+-------+----------------+----------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling ML Pipeline to transform the data\n",
    "\n",
    "# Representing categorical feature to numeric.\n",
    "encoder = StringIndexer(inputCol= 'Vendor_Code', outputCol= 'Vendor_Code_index')\n",
    "\n",
    "# Tokenization of text data for proccessing.\n",
    "tokenizer = Tokenizer(inputCol=\"Lower_Item_Description\", outputCol=\"token_text\")\n",
    "\n",
    "# Stopwords removal ( Cleaning phase ).\n",
    "stopwords = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "\n",
    "# Words by their counts.\n",
    "count_vect = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
    "\n",
    "# Term frequency * Inverse document frquency for obtaining text data weights.\n",
    "tf_idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "\n",
    "# Representing target categorical feature to numeric.\n",
    "# target_encoding = StringIndexer(inputCol='Product_Category',outputCol='label')\n",
    "\n",
    "# Representing target categorical feature to numeric.\n",
    "important_features = VectorAssembler(inputCols=['Vendor_Code_index','Inv_Amt','tf_idf'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "transorfer_pipeline = Pipeline(stages=[encoder,tokenizer,stopwords,count_vect,tf_idf,important_features]) #target_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the transformation process on training data.\n",
    "transformer = transorfer_pipeline.fit(final_df)\n",
    "\n",
    "# Final transformation on training data.\n",
    "final_train_data = transformer.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data\n",
    "\n",
    "# ML Model data preparation.\n",
    "# final_train_data.select('Product_Category').distinct().collect()\n",
    "\n",
    "validation_key = product_categories['vald']\n",
    "train_test_df = final_train_data.filter((col(\"Product_Category\") !=validation_key ))\n",
    "validation_df = final_train_data.filter((col(\"Product_Category\") ==validation_key ))\n",
    "(train_df,test_df) = train_test_df.randomSplit([0.7,0.3])\n",
    "\n",
    "train_df = train_df.select('label','features')\n",
    "test_df = test_df.select('label','features')\n",
    "validation_df = validation_df.select('Inv_Id','label','features')\n",
    "\n",
    "# train_df = train_df.select('label','features')\n",
    "# test_df = test_df.select('label','features')\n",
    "# validation_df = validation_df.select('label','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Naive Bayes model.\n",
    "# Better Model for Multiclassification having a NLP data.\n",
    "nb = NaiveBayes(featuresCol='features',smoothing=1.0,modelType='multinomial')\n",
    "\n",
    "product_predictor = nb.fit(train_df)\n",
    "test_results = product_predictor.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting Product category is: 90.44736809309904\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metric\n",
    "# \n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting Product category is: {}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|   22|(2654,[0,1,10,11,...|[-435.73812815629...|[9.16052783553018...|      22.0|\n",
      "|   22|(2654,[0,1,10,11,...|[-430.86398681131...|[5.06491753031984...|      22.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|   30|(2654,[0,1,10,21,...|[-878.30675586042...|[1.73960516366362...|      25.0|\n",
      "|   30|(2654,[0,1,2,9,28...|[-568.12377705213...|[5.59753144454322...|      28.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation submission data\n",
    "valid_results = product_predictor.transform(validation_df.select('label','features'))\n",
    "valid_results.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 278)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_results.count(),validation_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, row_number, monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "validation_df = validation_df.withColumn('id', row_number().over(Window.orderBy(monotonically_increasing_id())) - 1)\n",
    "valid_results = valid_results.withColumn('id', row_number().over(Window.orderBy(monotonically_increasing_id())) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = validation_df.select('id','Inv_Id').join(valid_results.select('id','prediction'),'id','outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+\n",
      "| id|Inv_Id|ProductCategory|\n",
      "+---+------+---------------+\n",
      "|  0| 15041|             25|\n",
      "|  1| 15094|             28|\n",
      "+---+------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_df = output_df.withColumn(\"ProductCategory\", col(\"prediction\").cast(IntegerType())).drop('prediction')\n",
    "output_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|Inv_Id|Product_Category|\n",
      "+------+----------------+\n",
      "| 15041|      CLASS-1274|\n",
      "| 15094|      CLASS-1963|\n",
      "| 15112|      CLASS-1758|\n",
      "| 15179|      CLASS-1522|\n",
      "| 15212|      CLASS-1758|\n",
      "+------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decoding Target feature\n",
    "product_categories_decode = {int(value) : key for (key, value) in product_categories.items()}\n",
    "map_func = udf(lambda row : product_categories_decode.get(row,row))\n",
    "\n",
    "# Finalising output\n",
    "output_df = output_df.withColumn(\"Product_Category\", map_func(col(\"ProductCategory\"))).drop('id','ProductCategory')\n",
    "output_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Submission CSV\n",
    "output_df.write.csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to disk\n",
    "nb.save(\"N_B_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
